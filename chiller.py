# -*- coding: utf-8 -*-
"""Copy of Chiller.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12a9MMIKW2_3jUmUxGibBpcKiZtxJEACX
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

!pip install seaborn
!pip install xgboost

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RandomizedSearchCV
import seaborn as sns

from google.colab import files

uploaded = files.upload()

from google.colab import files

uploaded1 = files.upload()

df1 = pd.read_csv('TableData (6).csv')
df2 = pd.read_csv('TableData (7).csv')
df3 = pd.read_csv('TableData (8).csv')
df4 = pd.read_excel('ECCO 19400(19400) sensors data (3).xlsx')
df5 = pd.read_excel('ECCO 19400(19400) sensors data (4).xlsx')
df6 = pd.read_excel('ECCO 19400(19400) sensors data (5).xlsx')

table_data = pd.concat([df1, df2, df3], ignore_index=True)
temp_data = pd.concat([df4, df5, df6], ignore_index=True)

table_data['Time'] = pd.to_datetime(table_data['Time'])
temp_data['DateTime'] = pd.to_datetime(temp_data['DateTime'])


merged_data = pd.merge_asof(
    table_data.sort_values('Time'),
    temp_data.sort_values('DateTime'),
    left_on='Time',
    right_on='DateTime',
    direction='nearest'
)


features = merged_data.drop(columns=['CH Load', 'Time', 'DateTime', 'CH1', 'CH2', 'CH3', 'CH4'])
target = merged_data['CH Load']


X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)


model = LinearRegression()
model.fit(X_train, y_train)


y_pred = model.predict(X_test)


mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)


print(f'Mean Squared Error: {mse:.2f}')
print(f'R^2 Score: {r2:.2f}')

coefficients = pd.DataFrame(model.coef_, features.columns, columns=['Coefficient'])
print(coefficients)

# Convert 'Time' to datetime if it's not already
merged_data['Time'] = pd.to_datetime(merged_data['Time'])

# Set Time as the index
merged_data.set_index('Time', inplace=True)

# Plotting the chiller load over time
plt.figure(figsize=(15, 6))
plt.plot(merged_data['CH Load'], label='Chiller Load', color='blue')
plt.title('Chiller Load Over Time')
plt.xlabel('Time')
plt.ylabel('Chiller Load (%)')
plt.legend()
plt.show()

relevant_features = ['CH Load', 'kW_Tot', 'kW_CHH', 'kW_CHP', 'Temperature [째C]', 'WBT_C', 'GPM', 'DeltaCHW']
correlation_data = merged_data[relevant_features]

# Calculate the correlation matrix
correlation_matrix = correlation_data.corr()

# Print the correlation matrix
print(correlation_matrix)

# Visualize the correlation matrix using a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title('Correlation Matrix')
plt.show()

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import matplotlib.pyplot as plt


df1 = pd.read_csv('TableData (6).csv')
df2 = pd.read_csv('TableData (7).csv')
df3 = pd.read_csv('TableData (8).csv')
df4 = pd.read_excel('ECCO 19400(19400) sensors data (3).xlsx')
df5 = pd.read_excel('ECCO 19400(19400) sensors data (4).xlsx')
df6 = pd.read_excel('ECCO 19400(19400) sensors data (5).xlsx')

def fill_missing_values(df):
    numeric_cols = df.select_dtypes(include=['number']).columns
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
    return df

dataframes = [df1, df2, df3, df4, df5, df6]
filled_dataframes = [fill_missing_values(df) for df in dataframes]
df1, df2, df3, df4, df5, df6 = filled_dataframes


table_data = pd.concat([df1, df2, df3], ignore_index=True)
temp_data = pd.concat([df4, df5, df6], ignore_index=True)

# Convert Time and DateTime to datetime objects
table_data['Time'] = pd.to_datetime(table_data['Time'])
temp_data['DateTime'] = pd.to_datetime(temp_data['DateTime'])

# Merge the datasets on Time
merged_data = pd.merge_asof(
    table_data.sort_values('Time'),
    temp_data.sort_values('DateTime'),
    left_on='Time',
    right_on='DateTime',
    direction='nearest'
)

# Select features and target variable
features = merged_data[['kW_CHH', 'kW_Tot', 'Temperature [째C]', 'kW_CHP', 'WBT_C', 'GPM']]
target = merged_data['CH Load']

# Normalize the features
scaler = MinMaxScaler()
scaled_features = scaler.fit_transform(features)
scaled_target = scaler.fit_transform(target.values.reshape(-1, 1))

# Create sequences for LSTM
def create_sequences(data, target, time_step=1):
    X, y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:(i + time_step), :])
        y.append(target[i + time_step])
    return np.array(X), np.array(y)


X, y = create_sequences(scaled_features, scaled_target, time_step=10)


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))  # Output layer

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))

# Predicting the chiller load
y_pred = model.predict(X_test)

# Inverse transform the predicted values to the original scale
y_pred = scaler.inverse_transform(y_pred)
y_test = scaler.inverse_transform(y_test)

from sklearn.metrics import mean_squared_error, r2_score

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print('Mean Squared Error:', mse)
print('R^2 Score:', r2)

plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual CH Load')
plt.plot(y_pred, label='Predicted CH Load')
plt.title('Chiller Load Prediction using LSTM')
plt.xlabel('Time Steps')
plt.ylabel('Chiller Load')
plt.legend()
plt.show()



def calculate_thresholds(df, feature, n=1):
    mean = df[feature].mean()
    std_dev = df[feature].std()

    lower_threshold = mean - (n * std_dev)
    upper_threshold = mean + (n * std_dev)

    return lower_threshold, upper_threshold


features = ['kW_CHH', 'kW_Tot', 'kW_CHP', 'Temperature [째C]', 'WBT_C', 'GPM']

thresholds = {}
for feature in features:
    try:
        thresholds[feature] = calculate_thresholds(merged_data, feature)
    except KeyError:
        print(f"Feature '{feature}' not found in merged_data.")


print(thresholds)

print("DataFrame 1 Columns:", df1.columns.tolist())
print("DataFrame 4 Columns:", df4.columns.tolist())

y_pred = y_pred.reshape(-1)
y_test = y_test.reshape(-1)


max_load = merged_data['CH Load'].max()


def determine_optimal_temperature(predicted_load_series, max_load):
    optimal_temperatures = []


    for load in predicted_load_series:
        if load > 0.7 * max_load:
            optimal_temperatures.append(28)
        elif load > 0.6 * max_load:
            optimal_temperatures.append(29)
        elif load > 0.5 * max_load:
            optimal_temperatures.append(30)
        elif load > 0.4 * max_load:
            optimal_temperatures.append(31)
        else:
            optimal_temperatures.append(32)

    return optimal_temperatures


optimal_temperatures_celsius = determine_optimal_temperature(y_pred, max_load)


print("Optimal Temperatures in Celsius:", optimal_temperatures_celsius)

def adjust_frequencies(optimal_temperatures):
    frequency_settings_list = []


    for temperature in optimal_temperatures:
        if temperature <= 29:
            frequency_settings_list.append({'Hz_CHP': 48, 'Hz_CHS': 48, 'Hz_CDS': 48, 'Hz_CT': 48})
        elif temperature <= 30:
            frequency_settings_list.append({'Hz_CHP': 47, 'Hz_CHS': 47, 'Hz_CDS': 47, 'Hz_CT': 47})
        elif temperature <= 31:
            frequency_settings_list.append({'Hz_CHP': 46, 'Hz_CHS': 46, 'Hz_CDS': 46, 'Hz_CT': 46})
        else:
            frequency_settings_list.append({'Hz_CHP': 45, 'Hz_CHS': 45, 'Hz_CDS': 45, 'Hz_CT': 45})

    return frequency_settings_list


frequency_settings_list = adjust_frequencies(optimal_temperatures_celsius)


print("Frequency Settings List:", frequency_settings_list)

!pip install Pillow

sns.boxplot(x=optimal_temperatures_celsius, y=y_pred)

# Add labels
plt.title('Box Plot: Predicted Load vs. Optimized Temperature')
plt.xlabel('Optimized Temperature (째C)')
plt.ylabel('Predicted Chiller Load (kW)')
plt.show()

def calculate_efficiency_score(y_actual, y_predicted):

    percentage_diff = np.abs((y_actual - y_predicted) / y_actual)


    efficiency_score = 100 * (1 - percentage_diff)

    return efficiency_score


efficiency_scores = calculate_efficiency_score(y_test, y_pred)


print("Chiller Efficiency Scores (%):", efficiency_scores)

low_threshold = 80
medium_threshold = 70
high_threshold = 60
critical_threshold = 50

anomaly_classifications = []


for score in efficiency_scores:
    if score < critical_threshold:
        anomaly_classifications.append("Critical")
    elif score < high_threshold:
        anomaly_classifications.append("High")
    elif score < medium_threshold:
        anomaly_classifications.append("Medium")
    elif score < low_threshold:
        anomaly_classifications.append("Low")
    else:
        anomaly_classifications.append("Normal")


anomalous_indices = [i for i, classification in enumerate(anomaly_classifications) if classification != "Normal"]


for i in anomalous_indices:
    print(f"Anomaly detected at index {i}: Efficiency = {efficiency_scores[i]:.2f}%, Classification = {anomaly_classifications[i]}")

def calculate_energy_saved(actual_load, predicted_load):
    energy_saved = ((actual_load - predicted_load) / actual_load) * 100
    return energy_saved

energy_saved_list = calculate_energy_saved(y_test, y_pred)

print("Energy Saved (%):", energy_saved_list)

time_index = np.arange(len(efficiency_scores))

# Plotting the Efficiency Scores
plt.figure(figsize=(12, 6))
plt.plot(time_index, efficiency_scores, marker='o', linestyle='-', color='blue', markersize=4)

# Enhancing the plot
plt.title('Chiller Efficiency Scores Over Time', fontsize=16)
plt.xlabel('Samples (or Time Steps)', fontsize=14)
plt.ylabel('Efficiency Score (%)', fontsize=14)
plt.xticks(time_index[::10])  # Show every 10th label for clarity
plt.axhline(y=90, color='red', linestyle='--', label='90% Efficiency Threshold')  # Example threshold line
plt.fill_between(time_index, efficiency_scores, 90, where=(efficiency_scores >= 90),
                 color='green', alpha=0.1, label='Above 90% Efficiency')  # Fill area above 90%
plt.fill_between(time_index, efficiency_scores, 90, where=(efficiency_scores < 90),
                 color='orange', alpha=0.1, label='Below 90% Efficiency')  # Fill area below 90%
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

time_index = np.arange(len(energy_saved_list))

plt.figure(figsize=(12, 6))
plt.plot(time_index, energy_saved_list, marker='o', linestyle='dotted', color='green', markersize=4)


plt.title('Energy Saved Over Time', fontsize=16)
plt.xlabel('Samples (or Time Steps)', fontsize=14)
plt.ylabel('Energy Saved (%)', fontsize=14)
plt.xticks(time_index[::10])
plt.axhline(y=0, color='red', linestyle='dashdot', label='No Energy Saved Threshold')
plt.fill_between(time_index, energy_saved_list, 0, where=(energy_saved_list >= 0),
                 color='green', alpha=0.1, label='Energy Saved')
plt.fill_between(time_index, energy_saved_list, 0, where=(energy_saved_list < 0),
                 color='orange', alpha=0.1, label='Energy Lost')
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

!pip install plotly

import plotly.graph_objects as go
time_index = np.arange(len(efficiency_scores))

# Create a Plotly figure
fig_efficiency = go.Figure()

# Add a scatter plot for efficiency scores
fig_efficiency.add_trace(go.Scatter(x=time_index, y=efficiency_scores, mode='lines+markers', name='Efficiency Score',
                                     line=dict(color='blue'), marker=dict(size=5)))

# Update layout
fig_efficiency.update_layout(title='Chiller Efficiency Scores Over Time',
                              xaxis_title='Samples (or Time Steps)',
                              yaxis_title='Efficiency Score (%)',
                              xaxis=dict(showgrid=True),
                              yaxis=dict(showgrid=True),
                              hovermode='closest')

# Show the interactive plot
fig_efficiency.show()

time_index = np.arange(len(energy_saved_list))

# Create a Plotly figure
fig_energy = go.Figure()

# Add a scatter plot for energy saved
fig_energy.add_trace(go.Scatter(x=time_index, y=energy_saved_list, mode='lines+markers', name='Energy Saved',
                                 line=dict(color='green'), marker=dict(size=5)))

# Update layout
fig_energy.update_layout(title='Energy Saved Over Time',
                         xaxis_title='Samples (or Time Steps)',
                         yaxis_title='Energy Saved (%)',
                         xaxis=dict(showgrid=True),
                         yaxis=dict(showgrid=True),
                         hovermode='closest')

# Show the interactive plot
fig_energy.show()

